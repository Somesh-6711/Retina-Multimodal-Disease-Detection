# Multimodal Retina Disease Detection (Fundus + OCT Fusion)

This project implements a **multimodal deep learning pipeline** for retinal disease detection using **fundus photographs** and **OCT B-scans**, closely mirroring the workflows used in real ophthalmology AI research labs.

We train three models:

1ï¸âƒ£ **Fundus-only CNN for diabetic retinopathy severity classification**  
2ï¸âƒ£ **OCT-only CNN for structural retinal disease classification**  
3ï¸âƒ£ **Fusion model combining both modalities for binary disease detection**

The key idea:
> ğŸ§  **Fundus shows surface vascular damage, OCT shows structural retinal layers â€” together they provide a stronger diagnostic signal than either alone.**

---

## ğŸ“Œ Dataset Sources

### **Fundus (APTOS 2019 Diabetic Retinopathy Dataset)**
- 3662 labelled color fundus photographs
- 5-class DR severity scale:

0 â€“ No DR
1 â€“ Mild
2 â€“ Moderate
3 â€“ Severe
4 â€“ Proliferative DR


### **OCT (Kermany 2018 Retinal OCT Dataset)**
- Four OCT disease classes:

CNV
DME
DRUSEN
NORMAL


> Note: datasets are **not from the same patients** â€” we align classes to build *virtual multimodal pairs* for fusion.

---

## ğŸ§± Pipeline Overview

### **1ï¸âƒ£ Fundus DR Classification (EfficientNet-B0)**

- Input: RGB fundus image  
- Task: 5-class DR severity  
- Loss: Cross-entropy  
- Augmentation: flips, rotations, color jitter  
- Implementation: `timm` + `PyTorch`

ğŸ“ˆ **Validation Accuracy â‰ˆ 0.81**

Most confident on:
âœ” No DR  
âœ” Moderate DR  

More challenging:
âš  Severe / proliferative (rare classes)

---

## ğŸ‘ Fundus Explainability (Grad-CAM)

Grad-CAM highlights lesions such as:

- microaneurysms
- hemorrhages
- exudates

<p align="center">
<img src="outputs/fundus/gradcam/6733544ae7a6_true2_pred2_gradcam.png" width="450">
</p>

<p align="center">
<i>Example Grad-CAM localization on a diabetic retinopathy fundus image</i>
</p>

---

## **2ï¸âƒ£ OCT Disease Classification (ResNet-18)**

- Input: grayscale OCT B-scan  
- Task: 4-class disease classification  
- Classes: CNV, DME, DRUSEN, NORMAL  
- Training on balanced subset of 3200 samples  
- Validation set: 32 images  

ğŸ“ˆ **Validation Accuracy â‰ˆ 1.00**  
(This dataset is relatively â€œcleanâ€ and separable)

---

## ğŸ§  OCT Explainability (Grad-CAM)

Grad-CAM highlights structural disruptions in retinal layers.

<p align="center">
<img src="outputs/oct/gradcam/CNV-8598714-1_trueCNV_predCNV_gradcam.png" width="450">
</p>

<p align="center">
<i>Grad-CAM highlighting CNV lesion in OCT</i>
</p>

---

## **3ï¸âƒ£ Multimodal Fusion Model**

We freeze both encoders:


> Note: datasets are **not from the same patients** â€” we align classes to build *virtual multimodal pairs* for fusion.

---

## ğŸ§± Pipeline Overview

### **1ï¸âƒ£ Fundus DR Classification (EfficientNet-B0)**

- Input: RGB fundus image  
- Task: 5-class DR severity  
- Loss: Cross-entropy  
- Augmentation: flips, rotations, color jitter  
- Implementation: `timm` + `PyTorch`

ğŸ“ˆ **Validation Accuracy â‰ˆ 0.81**

Most confident on:
âœ” No DR  
âœ” Moderate DR  

More challenging:
âš  Severe / proliferative (rare classes)

---

## ğŸ‘ Fundus Explainability (Grad-CAM)

Grad-CAM highlights lesions such as:

- microaneurysms
- hemorrhages
- exudates

<p align="center">
<img src="outputs/fundus/gradcam/6733544ae7a6_true2_pred2_gradcam.png" width="450">
</p>

<p align="center">
<i>Example Grad-CAM localization on a diabetic retinopathy fundus image</i>
</p>

---

## **2ï¸âƒ£ OCT Disease Classification (ResNet-18)**

- Input: grayscale OCT B-scan  
- Task: 4-class disease classification  
- Classes: CNV, DME, DRUSEN, NORMAL  
- Training on balanced subset of 3200 samples  
- Validation set: 32 images  

ğŸ“ˆ **Validation Accuracy â‰ˆ 1.00**  
(This dataset is relatively â€œcleanâ€ and separable)

---

## ğŸ§  OCT Explainability (Grad-CAM)

Grad-CAM highlights structural disruptions in retinal layers.

<p align="center">
<img src="outputs/oct/gradcam/CNV-8598714-1_trueCNV_predCNV_gradcam.png" width="450">
</p>

<p align="center">
<i>Grad-CAM highlighting CNV lesion in OCT</i>
</p>

---

## **3ï¸âƒ£ Multimodal Fusion Model**

We freeze both encoders:

z_fundus = EfficientNet-B0 embedding
z_oct = ResNet-18 embedding


Then concatenate and train an **MLP classifier**:

z = concat(z_fundus , z_oct)


### **Task**
Binary classification:

normal = DR grade 0 + OCT NORMAL
disease = DR 1â€“4 + OCT CNV/DME/DRUSEN


Dataset:
- 3000 paired samples  
- 2400 train / 600 validation  

ğŸ“ˆ **Fusion Validation Accuracy = 0.995**

| Model           | Modality        | Task                         | Validation Accuracy |
|-----------------|-----------------|-----------------------------|---------------------|
| Fundus-only     | Fundus          | 5-class DR                  | ~0.81               |
| OCT-only        | OCT             | 4-class disease             | ~1.00 (n=32)        |
| Fusion          | Fundus + OCT    | Binary normal vs disease    | **0.995**           |

âœ” Fusion outperforms fundus-only  
âœ” Fusion produces extremely robust binary screening performance  
âœ” Shows **complementary value of multimodal imaging**

---

## ğŸ“¸ Before â†’ After (Explainability View)

### Fundus: Raw â†’ Grad-CAM

<p align="center">
  <img src="outputs/fundus/gradcam/e1fb532f55df_true3_pred4_gradcam.png" width="500">
</p>

---

### OCT: Raw â†’ Grad-CAM

<p align="center">
  <img src="outputs/oct/gradcam/DME-9583225-1_trueDME_predDME_gradcam.png" width="500">
</p>

---

## ğŸ§ª Training Logs (Highlights)

### Fundus (EffNet-B0)
Best validation accuracy: 0.8131


### Fusion (MLP Head)
Best validation accuracy: 0.9950


Macro-F1 for both classes â‰ˆ **0.99**

---

## ğŸ“¦ Tech Stack

- **PyTorch**
- **timm**
- **Albumentations**
- **scikit-learn**
- **Grad-CAM**
- **NumPy / Pandas**
- **Matplotlib**

---

## ğŸ‘©â€âš•ï¸ Clinical Relevance

- Fundus = vascular & surface biomarkers  
- OCT = retinal microstructure  
- Fusion â‰ˆ clinical workflow  
- Explainability builds trust  
- Binary disease vs normal supports **screening pipelines**

This project demonstrates:

âœ” multimodal medical AI  
âœ” deep learning engineering  
âœ” explainability  
âœ” clinical-style evaluation  
âœ” reproducible pipeline design  

---

## ğŸš€ Future Extensions

- Train full OCT dataset
- Multi-class fusion (not just binary)
- Add SHAP interpretability
- Patient-level aggregation
- Deploy via Streamlit

---

## ğŸ“ Repo Structure


Macro-F1 for both classes â‰ˆ **0.99**

---

## ğŸ“¦ Tech Stack

- **PyTorch**
- **timm**
- **Albumentations**
- **scikit-learn**
- **Grad-CAM**
- **NumPy / Pandas**
- **Matplotlib**

---

## ğŸ‘©â€âš•ï¸ Clinical Relevance

- Fundus = vascular & surface biomarkers  
- OCT = retinal microstructure  
- Fusion â‰ˆ clinical workflow  
- Explainability builds trust  
- Binary disease vs normal supports **screening pipelines**

This project demonstrates:

âœ” multimodal medical AI  
âœ” deep learning engineering  
âœ” explainability  
âœ” clinical-style evaluation  
âœ” reproducible pipeline design  

---

## ğŸš€ Future Extensions

- Train full OCT dataset
- Multi-class fusion (not just binary)
- Add SHAP interpretability
- Patient-level aggregation
- Deploy via Streamlit

---

## ğŸ“ Repo Structure

data/
outputs/
src/
models/


---
