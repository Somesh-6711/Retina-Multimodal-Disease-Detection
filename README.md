# Multimodal Retina Disease Detection (Fundus + OCT Fusion)

This project implements a **multimodal deep learning pipeline** for retinal disease detection using **fundus photographs** and **OCT B-scans**, mirroring how modern ophthalmology labs combine multiple imaging modalities in practice.

We train three models:

1. ğŸ©º **Fundus-only CNN** for diabetic retinopathy (DR) severity classification  
2. ğŸ‘ **OCT-only CNN** for structural retinal disease classification  
3. ğŸ”— **Fusion model** that combines fundus + OCT embeddings for binary disease detection  

> ğŸ§  **Fundus captures surface vascular damage, OCT captures retinal layer structure â€“ together they provide a stronger diagnostic signal than either alone.**

---

## ğŸ“Œ Dataset Sources

### 1ï¸âƒ£ Fundus â€“ APTOS 2019 Diabetic Retinopathy

- 3662 labeled color fundus photographs  
- 5-class DR severity scale:
  - `0` â€“ No DR  
  - `1` â€“ Mild  
  - `2` â€“ Moderate  
  - `3` â€“ Severe  
  - `4` â€“ Proliferative DR  

Fundus images are used to train the **DR severity classifier**.

---

### 2ï¸âƒ£ OCT â€“ Kermany 2018 Retinal OCT

- Grayscale OCT B-scans  
- 4 disease classes:
  - `CNV`  
  - `DME`  
  - `DRUSEN`  
  - `NORMAL`  

OCT images are used to train the **OCT disease classifier** and to provide the second modality for fusion.

> âš ï¸ The fundus and OCT datasets are **not from the same patients**. For the fusion model, we align labels (normal vs disease) and create *virtual multimodal pairs*.

---

## ğŸ§± Pipeline Overview

```mermaid
flowchart LR
    F[Fundus image] --> FEnc[Fundus Encoder (EffNet-B0)]
    O[OCT B-scan]   --> OEnc[OCT Encoder (ResNet-18)]
    FEnc --> Z[Concatenate embeddings]
    OEnc --> Z
    Z --> Head[MLP Fusion Head]
    Head --> Y[Normal vs Disease]
```

Core steps:

1. Train fundus DR classifier

2. Train OCT disease classifier

3. Freeze both encoders and train a fusion head on top of concatenated embeddings

4. Use Grad-CAM to visualize where each model is â€œlookingâ€

## ğŸ©º Model 1 â€“ Fundus DR Classification (EfficientNet-B0)

Backbone: tf_efficientnet_b0 (via timm)

Input: RGB fundus image

Task: 5-class DR severity

Loss: Cross-entropy

Augmentation: flips, rotations, brightness/contrast and color jitter

Framework: PyTorch + timm + Albumentations

Validation Accuracy: ~0.81

Most confident on:

âœ… No DR

âœ… Moderate DR

More challenging:

âš  Severe / proliferative DR (class imbalance & subtle differences)

## ğŸ‘ Fundus Explainability (Grad-CAM)

Grad-CAM is used to highlight lesions such as:

microaneurysms

hemorrhages

exudates

âœ… Correct prediction example
<p align="center"> <img src="outputs/fundus/gradcam/6733544ae7a6_true2_pred2_gradcam.png" width="450"> </p> <p align="center"> <i>Moderate DR â€“ correctly classified (true = 2, pred = 2).</i> </p>
âš  Misclassification example
<p align="center"> <img src="outputs/fundus/gradcam/e1fb532f55df_true3_pred4_gradcam.png" width="450"> </p> <p align="center"> <i>Severe DR â€“ model over-grades to proliferative DR (true = 3, pred = 4).</i> </p>

These visualizations help verify that the network is focusing on clinically plausible structures rather than artifacts.

## ğŸ§  Model 2 â€“ OCT Disease Classification (ResNet-18)

Backbone: resnet18

Input: single-channel OCT B-scan

Task: 4-class disease classification

CNV, DME, DRUSEN, NORMAL

Training set: balanced subset of 3200 images (max 800 per class)

Validation set: 32 images (fast sanity-check set)

Loss: Cross-entropy

Validation Accuracy: ~1.00 on the small validation split

(The dataset is relatively clean and the classes are highly separable.)

## ğŸ§  OCT Explainability (Grad-CAM)

Grad-CAM highlights structural disruptions in retinal layers for different disease types.

Example â€“ DME
<p align="center"> <img src="outputs/oct/gradcam/DME-9583225-1_trueDME_predDME_gradcam.png" width="450"> </p> <p align="center"> <i>OCT Grad-CAM focusing on edema-related structural changes (DME).</i> </p>
Example â€“ CNV
<p align="center"> <img src="outputs/oct/gradcam/CNV-8598714-1_trueCNV_predCNV_gradcam.png" width="450"> </p> <p align="center"> <i>OCT Grad-CAM highlighting CNV lesion region.</i> </p>

## Model 3 â€“ Multimodal Fusion Head

We first freeze the trained encoders:

z_fundus = EfficientNet-B0 embedding
z_oct    = ResNet-18 embedding


Then we concatenate them:

z = concat(z_fundus, z_oct)


and train a small MLP classifier on top.

## ğŸ“Š Result Summary

| Model              | Modality        | Task                         | Validation Accuracy |
|--------------------|-----------------|-----------------------------|---------------------|
| Fundus CNN         | Fundus          | 5-class DR severity         | ~0.81               |
| OCT CNN            | OCT             | 4-class disease             | ~1.00 (n = 32)      |
| Fusion MLP Head    | Fundus + OCT    | Binary normal vs disease    | **0.995**           |

### Key Takeaways
- âœ… **Fusion outperforms fundus-only screening**
- ğŸ‘ **OCT captures structural pathology very strongly**
- ğŸ”— **Multimodal imaging = stronger diagnostic signal**
- ğŸ¥ **Matches real-world retina clinic workflow**

## ğŸ‘ Before â†’ After Explainability â€” Markdown Code
ğŸ“¸ Before â†’ After: Model Explainability Views

## ğŸ‘ Fundus Explainability â€” Raw vs Grad-CAM

<p align="center">
  <img src="outputs/fundus/gradcam/e1fb532f55df_true3_pred4_gradcam.png" width="520">
</p>

<p align="center">
  <i>
  Grad-CAM overlay highlighting DR-related vascular abnormalities on fundus photography.
  (True label = Severe DR, Predicted = Proliferative DR)
  </i>
</p>


## ğŸ§  OCT Explainability â€” Raw vs Grad-CAM

<p align="center">
  <img src="outputs/oct/gradcam/DME-9583225-1_trueDME_predDME_gradcam.png" width="520">
</p>

<p align="center">
  <i>
  Grad-CAM visualization showing model attention on macular edema-related structural changes.
  (True label = DME, Predicted = DME)
  </i>
</p>


## ğŸ“¦ Tech Stack

PyTorch â€“ core deep learning framework

timm â€“ modern CNN backbones (EfficientNet, ResNet)

Albumentations â€“ image augmentation

scikit-learn â€“ metrics & utilities

Grad-CAM â€“ model explainability

NumPy / Pandas / Matplotlib â€“ data & visualization

## ğŸ‘©â€âš•ï¸ Clinical Relevance

Fundus = vascular & surface biomarkers

OCT = retinal microstructure & macular fluid

Fusion â‰ˆ how ophthalmologists combine modalities when making decisions

Grad-CAM provides visual evidence for where the network is focusing, which is crucial for trust in medical AI

Binary disease vs normal supports screening workflows and referral triage

This project demonstrates:

Multimodal medical AI

Deep learning engineering end-to-end

Explainability and rigorous evaluation

Reproducible, research-style pipeline design

## ğŸš€ Future Extensions

Train on the full OCT dataset and larger val/test splits

Multiclass fusion (joint DR grade + OCT subtype prediction)

SHAP / Integrated Gradients for richer interpretability

Patient-level aggregation and calibration analysis

Lightweight demo app (Streamlit / FastAPI) for clinicians